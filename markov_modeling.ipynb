{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac190cca",
   "metadata": {},
   "source": [
    "# Info\n",
    "This notebook works pretty differently from txt_from_web.ipynb. The other notebook is meant to get a bunch of text files for you to analyze. In theory, you would go through it, get what you want, and go back to it as-needed for more text. \n",
    "\n",
    "By contrast, this notebook is more interactive, and you're intended to fill certain blocks with your own code to make use of the main object: marky the Markov Model Manager! The functions you can make use of are described in the code blocks, but I'll also have a block with examples of the functions being used, and how you might make use of a Markov Model Manager object.\n",
    "\n",
    "The main idea is that marky will take the folder you set in section 0 as `root`, create any missing folders, and allow you to handle file management and markov model building all in one place! You can:\n",
    "\n",
    "* import text files and turn them into markov models\n",
    "* import markov models from json files\n",
    "* create new models and then export them as json files\n",
    "* combine models and export the result as a json file\n",
    "* create formatted sentence outputs for any model so you can test models and fiddle with settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593842a",
   "metadata": {},
   "source": [
    "# 0. Universal Stuff - Run First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "9dc8f51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import markovify\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# defines class that extends markovify model by incorporating part-of-speech tagging\n",
    "# note that using POSifiedText(string) over markovify.Text(string) will take a lot longer\n",
    "class POSifiedText(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return [\"::\".join((word.orth_,word.pos_)) for word in nlp(sentence)]\n",
    "    \n",
    "    def word_join(self, words):\n",
    "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
    "        return sentence\n",
    "\n",
    "# note the / at the end!! no matter how long the folder path, it needs to end in / or shit breaks\n",
    "root = \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204e3d8",
   "metadata": {},
   "source": [
    "# 1. Markov Model Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "734a2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class markovManager(dict):\n",
    "    def __init__(self, root_folder):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        self.root_folder = root_folder\n",
    "        self.txts_folder = self.root_folder+\"txts/\"\n",
    "        self.jsons_folder = self.root_folder+\"jsons/\"\n",
    "        self.directory_setup()\n",
    "        self.txts = self.folder_to_dict(self.txts_folder)\n",
    "        self.jsons = self.folder_to_dict(self.jsons_folder)\n",
    "        self.models = {key:self.json_interpreter(self.jsons[key]) for key in self.jsons.keys()}\n",
    "    \n",
    "    def directory_setup(self):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        for folder in [self.root_folder, self.txts_folder, self.jsons_folder]:\n",
    "            if os.path.isdir(folder) == False:\n",
    "                path_out = (os.getcwd()+\"/\"+folder).replace(\"\\\\\", \"/\")\n",
    "                print(\"creating {}\".format(path_out))\n",
    "                os.mkdir(folder)\n",
    "    \n",
    "    def file_reader(self, path):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        with open(path, 'r', errors=\"ignore\") as f:\n",
    "            content = f.read()\n",
    "        return content\n",
    "    \n",
    "    def json_interpreter(self, json):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        if \"::\" in json:\n",
    "            model = POSifiedText.from_json(json)\n",
    "        else:\n",
    "            model = markovify.Text.from_json(json)\n",
    "        return model\n",
    "    \n",
    "    def folder_to_dict(self, folder):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        files = dict()\n",
    "        filenames = os.listdir(folder)\n",
    "        for filename in filenames:\n",
    "            filename_noext, filename_ext = filename.rsplit(\".\")\n",
    "            content = self.file_reader(folder+filename)\n",
    "            files[filename_noext] = content\n",
    "        return files\n",
    "  \n",
    "    def update(self):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        for (folder, dictionary) in [(self.txts_folder, self.txts), (self.jsons_folder, self.jsons)]:\n",
    "            filenames = os.listdir(folder)\n",
    "            for filename in filenames:\n",
    "                filename_noext, filename_ext = filename.rsplit(\".\")\n",
    "                if filename_noext not in dictionary.keys() and filename_ext == \"txt\":\n",
    "                     dictionary[filename_noext] = self.file_reader(folder+filename)\n",
    "                elif filename_noext not in dictionary.keys() and filename_ext == \"json\":\n",
    "                    dictionary[filename_noext] = self.file_reader(folder+filename)\n",
    "                    new_model = self.json_interpreter(dictionary[filename_noext])\n",
    "                    self.models[filename_noext] = new_model\n",
    "    \n",
    "    def add_model(self, name, string, pos=False, state_size=2):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        if pos == False:\n",
    "            model = markovify.Text(string, state_size=state_size)\n",
    "        elif pos == True:\n",
    "            model = POSifiedText(string, state_size=state_size)\n",
    "        self.models[name] = model\n",
    "        \n",
    "    def combine_models(self, name, model_names, weights=False):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        if weights == False:\n",
    "            weights = [1 for i in model_names]\n",
    "        models = list()\n",
    "        for model_name in model_names:\n",
    "            models.append(self.models[model_name])\n",
    "        model_combo = markovify.combine(models, weights)\n",
    "        self.models[name] = model_combo\n",
    "        \n",
    "    def export_model(self, model_name):\n",
    "        '''\n",
    "        tk\n",
    "        '''\n",
    "        model = self.models[model_name]\n",
    "        model_json = model.to_json()\n",
    "        self.jsons[model_name] = model_json\n",
    "        with open(self.jsons_folder+model_name+\".json\",'w') as f:\n",
    "            f.write(model_json)\n",
    "    \n",
    "    def output(self, model_name):\n",
    "        model = self.models[model_name]\n",
    "        sentence = model.make_sentence()\n",
    "        '''\n",
    "        Receives a string and returns a string (generally, a single sentence from a larger corpus).\n",
    "        Performs a sequence of removals/substitutions to normalize formatting and fix some common issues.\n",
    "        Note that these changes were largely determined by the files I was using, so you may need to adjust them.\n",
    "        '''\n",
    "        sentence = sentence.replace(\" ,\",\",\").replace(\" .\",\".\").replace(r'(?<=[^:]) \\.\\.\\.',\"...\").replace(\":...\",\": ...\")\\\n",
    "            .replace(\" ?\",\"?\").replace(\" !\",\"!\").replace(\" ;\",\";\").replace(\" :\",\":\").replace(\"  \",\" \").replace(\"   \",\"  \")\\\n",
    "            .replace(\"\\n\",\"\").replace(\" )\", \")\").replace(\"( \",\"(\").replace(\";;\",\";\").replace(\"::\",\":\")\n",
    "        try: \n",
    "            # this regex pattern fixes apostrophe errors for contractions, e.g. \"I 'm\" or \"do n't\"\n",
    "            patterns = [\"[A-Za-z]* '[a-z]\", \"[A-Za-z]* [a-z]'[a-z]\"]\n",
    "            for pattern in patterns:\n",
    "                matches = re.findall(pattern, sentence)\n",
    "                for match in matches:\n",
    "                    match_f = match.replace(\" \",\"\")\n",
    "                    sentence = sentence.replace(match, match_f)\n",
    "            # this regex pattern fixes apostrophe errors for questions and exclamations, e.g. \"Hi!It's\" or \"Yes?This\"\n",
    "            odd_pattern = \"[?!](?=[A-Z])\"\n",
    "            matches = re.findall(odd_pattern, sentence)\n",
    "            for match in matches:\n",
    "                sentence = sentence.replace(match, match+\" \")\n",
    "            if sentence[-1] == \" \":\n",
    "                sentence = sentence[0:-1]\n",
    "        except:\n",
    "            print(\"Sentence could not be generated, sorry. :( Try again, it might just be the model!\")\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "d3d1dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "marky = markovManager(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "3ef77110",
   "metadata": {},
   "outputs": [],
   "source": [
    "marky.add_model(\"gigi_transcripts_nopos\", marky.txts[\"gigi_transcripts\"])\n",
    "marky.combine_models(\"shabnak1\", [\"mystery\", \"gigi_transcripts_nopos\"], [1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "ac6a03eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pulling back the loaded drinks to Burton and then tossed the open bottle in on an armed man.'"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marky.output(\"shabnak1\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
